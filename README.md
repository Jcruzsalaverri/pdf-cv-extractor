# CV Screening System - README

A specialized Python system for processing, analyzing, and screening CVs using LLM-powered extraction and RAG (Retrieval Augmented Generation).

## ğŸ¯ What This System Does

**Transform CVs â†’ Searchable Database â†’ Intelligent Screening**

1. **Extract & Clean** - Pull text from PDFs and normalize formatting
2. **Structure Data** - Extract skills, experience, education using LLMs
3. **Enable Search** - Semantic + metadata search across candidates
4. **Rank & Compare** - Find the best candidates for your role

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure API Key

```bash
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

### 3. Process CVs

```bash
# Create folder with CVs
mkdir cvs
copy *.pdf cvs\

# Process all CVs
python batch_processor.py cvs
```

### 4. Search Candidates

```bash
# List all candidates
python metadata_store.py list

# Search by skill
python metadata_store.py search-skill Python

# Get statistics
python metadata_store.py stats
```

---

## ğŸ“‹ Core Pipeline

### **`batch_processor.py`** - Main Orchestrator

Processes CVs through the complete pipeline:

```bash
python batch_processor.py ./cvs_folder
```

**What it does:**

1. âœ… Extract text from PDFs (`extract_text.py`)
2. âœ… Clean formatting artifacts (`text_cleaner.py`)
3. âœ… Extract structured data (`cv_extractor.py`)
4. âœ… Generate embeddings (`embedding.py`)
5. âœ… Store in vector database (`vector_store.py`)
6. âœ… Index in metadata store (`metadata_store.py`)

**Output (in `data/` folder):**

- `CV_name_cleaned.txt` - Cleaned text
- `CV_name_extracted.json` - Structured data
- `CV_name_embeddings.json` - Embeddings
- `cv_metadata.json` - Searchable index

---

## ğŸ” Search & Query

### Metadata Search (Exact Matches)

```bash
# Search by skill
python metadata_store.py search-skill "Python"

# Search by experience
python metadata_store.py search-experience 5 10  # 5-10 years

# Search by company
python metadata_store.py search-company "SDG Group"

# List all candidates
python metadata_store.py list

# Get statistics
python metadata_store.py stats
```

### Individual Components

```bash
# Extract text only
python extract_text.py CV.pdf output.txt

# Clean text only
python text_cleaner.py CV.txt

# Extract structured data only
python cv_extractor.py CV_cleaned.txt
```

---

## ğŸ“Š Extracted Data Structure

Each CV is transformed into structured JSON:

```json
{
  "candidate_name": "John Doe",
  "email": "john.doe@example.com",
  "phone": "+1 555 0123 456",
  "total_years_experience": 5.5,
  "current_role": "Senior Developer",
  "companies": ["Tech Corp", "StartUp Inc"],
  "roles": ["Senior Developer", "Junior Developer"],
  "technical_skills": ["Python", "Machine Learning", "Cloud Computing"],
  "programming_languages": ["Python", "JavaScript"],
  "frameworks": ["Django", "React"],
  "tools": ["Docker", "Git", "AWS"],
  "degrees": [
    {
      "degree": "Master",
      "field": "Computer Science",
      "university": "Tech University",
      "year": "2018-2020"
    }
  ],
  "certifications": ["AWS Certified Solutions Architect"]
}
```

---

## ğŸ—ï¸ Project Structure

```
pdf-agent/
â”œâ”€â”€ Core Pipeline
â”‚   â”œâ”€â”€ extract_text.py          # PDF â†’ text
â”‚   â”œâ”€â”€ text_cleaner.py          # Clean formatting
â”‚   â”œâ”€â”€ cv_extractor.py          # Extract structured data
â”‚   â”œâ”€â”€ chunking.py              # Split into chunks
â”‚   â”œâ”€â”€ embedding.py             # Generate embeddings
â”‚   â””â”€â”€ batch_processor.py       # Orchestrate all steps
â”‚
â”œâ”€â”€ Database
â”‚   â”œâ”€â”€ vector_store.py          # ChromaDB (semantic search)
â”‚   â””â”€â”€ metadata_store.py        # JSON index (structured search)
â”‚
â”œâ”€â”€ Configuration
â”‚   â”œâ”€â”€ config.py                # Settings
â”‚   â”œâ”€â”€ .env                     # API keys (gitignored)
â”‚   â”œâ”€â”€ .env.example             # Template
â”‚   â””â”€â”€ requirements.txt         # Dependencies
â”‚
â”œâ”€â”€ Data (gitignored)
â”‚   â”œâ”€â”€ data/                    # Processed CVs
â”‚   â””â”€â”€ chroma_db/              # Vector database
â”‚
â”œâ”€â”€ Tests & Utilities
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_chunking.py
â”‚       â”œâ”€â”€ analyze_embeddings.py
â”‚       â””â”€â”€ debug_search.py
â”‚
â””â”€â”€ Documentation
    â”œâ”€â”€ README.md               # This file
    â”œâ”€â”€ QUICKSTART.md          # Quick start
    â””â”€â”€ docs/
        â”œâ”€â”€ TECHNICAL_GUIDE.md
        â”œâ”€â”€ RAG_PIPELINE_EXPLAINED.md
        â””â”€â”€ THEORETICAL_FOUNDATIONS.md
```

---

## âš™ï¸ Configuration

Edit `.env` file:

```bash
# LLM Provider (for text cleaning & extraction)
LLM_PROVIDER=gemini
GEMINI_API_KEY=your_key_here

# Embedding Model
EMBEDDING_MODEL=models/embedding-001

# Chunking
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# Retrieval
RETRIEVAL_TOP_K=5
```

---

## ğŸ“š Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Get started in 5 minutes
- **[TECHNICAL_GUIDE.md](docs/TECHNICAL_GUIDE.md)** - Complete technical reference
- **[RAG_PIPELINE_EXPLAINED.md](docs/RAG_PIPELINE_EXPLAINED.md)** - Deep dive into RAG
- **[THEORETICAL_FOUNDATIONS.md](docs/THEORETICAL_FOUNDATIONS.md)** - Why RAG works

---

## ğŸ”§ Requirements

- Python 3.8+
- PyMuPDF (PDF extraction)
- LangChain (LLM integration)
- ChromaDB (vector database)
- Google Gemini API key (for LLM & embeddings)

Install all:

```bash
pip install -r requirements.txt
```

---

## ğŸ’¡ Key Features

âœ… **LLM-powered extraction** - Intelligent data extraction from any CV format  
âœ… **Hybrid search** - Semantic (vector) + exact (metadata) search  
âœ… **Batch processing** - Process hundreds of CVs automatically  
âœ… **Structured data** - Skills, experience, education in JSON format  
âœ… **Persistent storage** - ChromaDB + JSON for fast queries  
âœ… **Production-ready** - Error handling, logging, progress tracking  

---

## ğŸ¯ Use Cases

- **Recruitment agencies** - Screen large volumes of candidates
- **HR departments** - Find qualified candidates quickly
- **Talent acquisition** - Build searchable candidate databases
- **Career services** - Analyze and compare CVs

---

## ğŸ“ License

MIT License - See LICENSE file for details

---

## ğŸ¤ Contributing

Contributions welcome! Please read CONTRIBUTING.md first.

---

**Built with â¤ï¸ using LangChain, ChromaDB, and Google Gemini**

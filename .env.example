# Google Gemini API Configuration (only needed if using EMBEDDING_PROVIDER=gemini)
GEMINI_API_KEY=your_api_key_here

# Anthropic Claude API Configuration (only needed if using LLM_PROVIDER=claude)
ANTHROPIC_API_KEY=your_api_key_here

# Text Chunking Configuration (optional)
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# Embedding Configuration
# ============================================
# EMBEDDING CONFIGURATION
# ============================================
# Provider: "local" (free, runs on your computer) or "gemini" (requires API key)
EMBEDDING_PROVIDER=local

# Local Embedding Model (used when EMBEDDING_PROVIDER=local)
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
# Popular options: all-MiniLM-L6-v2 (fast, 384 dims), all-mpnet-base-v2 (better quality, 768 dims)

# Gemini Embedding Model (used when EMBEDDING_PROVIDER=gemini)
EMBEDDING_MODEL=models/embedding-001

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=10

# LLM Provider Configuration
LLM_PROVIDER=gemini
# Options: "gemini" or "claude"

# LLM Models
GEMINI_MODEL=gemini-2.0-flash-exp
# Options: gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash

CLAUDE_MODEL=claude-3-5-sonnet-20241022
# Options: claude-3-5-sonnet-20241022, claude-3-opus-20240229

# LLM Temperature (0.0-1.0, lower = more focused, higher = more creative)
LLM_TEMPERATURE=0.7

# Retrieval Configuration
RETRIEVAL_TOP_K=5
# Number of chunks to retrieve for each query

RETRIEVAL_SCORE_THRESHOLD=0.5
# Minimum similarity score (0.0-1.0)

# Vector Database Path
VECTOR_DB_PATH=./chroma_db
